{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "l = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s][%(levelname)s]: %(message)s',\n",
    "                        level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing according to the pre-trained model\n",
    "# http://pytorch.org/docs/master/torchvision/models.html\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Scale(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "       mean=[0.485, 0.456, 0.406],\n",
    "       std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "    \n",
    "def prepare_image(image):\n",
    "    \"\"\"\n",
    "    Prepare image to be fed into the model.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # These preprocessing steps are taken from PyTorch's ImageNet example\n",
    "    return preprocess(image).unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.ImageFolder(\"./training\", preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = datasets.ImageFolder(\"./testing\", preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_ldr = torch.utils.data.DataLoader(ds_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_ldr = torch.utils.data.DataLoader(ds_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_function, optimizer, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Begin training the last layer\n",
    "    :param model: Model to train\n",
    "    :param loss_function: Use to assess the model\n",
    "    :praram optimizer:\n",
    "    :param num_epochs: Number of epochs to train on.\n",
    "    :return: best model\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    best_model = model\n",
    "    best_acc = 0\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        l.info(\"EPOCH: %d/%d\", e, num_epochs-1)\n",
    "        \n",
    "        for is_training in [True, False]:\n",
    "            model.train(is_training)\n",
    "            \n",
    "            if is_training:\n",
    "                # Train the model\n",
    "                for data, target in ds_train_ldr:\n",
    "                    x, y = Variable(data), Variable(target)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    r = model(x)\n",
    "                    _, preds = torch.max(r.data, 1)\n",
    "#                     l.info(\"Predictions: %s\", str(preds))\n",
    "                    \n",
    "                    loss = loss_function(r, y)\n",
    "#                     l.info(\"Loss: %s\", str(loss))\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            else:\n",
    "                v_loss = 0\n",
    "                v_acc = 0\n",
    "                \n",
    "                # Validate the model\n",
    "                for data, target in ds_test_ldr:\n",
    "                    x, y = Variable(data), Variable(target)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    r = model(x)\n",
    "                    _, preds = torch.max(r.data, 1)\n",
    "#                     l.info(\"Predictions: %s\", str(preds))\n",
    "                    \n",
    "                    loss = loss_function(r, y)\n",
    "#                     l.info(\"Loss: %s\", str(loss))\n",
    "                    \n",
    "                    v_loss += loss.data[0]\n",
    "                    v_acc += torch.sum(preds == y.data)\n",
    "                \n",
    "                epoch_loss = v_loss / len(ds_test)\n",
    "                epoch_acc = v_acc / len(ds_test)\n",
    "                \n",
    "                l.info(\"Epoch %d, loss %f, acc %f\", e, epoch_loss, epoch_acc)\n",
    "                \n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model = copy.deepcopy(model)\n",
    "    l.info(\"Complete. Best acc %f\", best_acc)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet152(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_conv\n",
    "# num_ftrs = model_conv.fc.in_features\n",
    "num_ftrs = 9216\n",
    "# model_conv.fc = nn.Linear(num_ftrs, 3)\n",
    "model_conv.classifier = nn.Linear(num_ftrs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model_conv.classifier.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-01 15:21:08,870][INFO]: EPOCH: 0/99\n"
     ]
    }
   ],
   "source": [
    "model_conv = train(\n",
    "    model=model_conv, \n",
    "    loss_function=loss_function, \n",
    "    optimizer=optimizer, \n",
    "    num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
